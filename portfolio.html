<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Meghana Reddy Pedolla - Data Engineer</title>
    <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="cssp3/portfolio.3.css">
</head>
<body>
    <!-- Navigation -->
    <nav class="navbar">
        <div class="nav-content">
            <div class="logo">My Portfolio</div>
            <div class="nav-links" id="navLinks">
                <a href="#about">About</a>
                <a href="#skills">Skills</a>
                <a href="#projects">Projects</a>
                <a href="#experience">Experience</a>
                <a href="#contact">Contact</a>
            </div>
            <div class="menu-btn" id="menuBtn">
                <i class="fas fa-bars"></i>
            </div>
        </div>
    </nav>

    <!-- Hero Section -->
    <section class="hero" id="hero">
        <div class="hero-content">
            <div class="hero-text">
                <p class="greeting">Hello, I'm</p>
                <h1>Meghana Reddy Pedolla</h1>
                <h2>Data Engineer</h2>
                <div class="contact-info">
                    <a href="mailto:meghanareddy1818@gmail.com">
                        <i class="fas fa-envelope"></i>
                        meghanareddy1818@gmail.com
                    </a>
                    <a href="tel:+16183195600">
                        <i class="fas fa-phone"></i>
                        +1-618-319-5600
                    </a>
                </div>
            </div>
            <div class="hero-image">
                <div class="profile-img">
                    <img src="imgp3/img_ak1.jpeg" alt="Meghana Reddy Pedolla">
                </div>
            </div>
        </div>
    </section>

    <!-- About Section -->
    <section class="about" id="about">
        <div class="container">
            <h2 class="section-title">About Me</h2>
            <p class="about-text">
                Results-driven Data Engineer with a strong foundation in big data processing, ETL pipelines, and cloud technologies. Proficient in Python, SQL, and PySpark, with hands-on experience in Azure Data Factory, Databricks, Snowflake, and AWS. Successfully automated data integration processes, optimized complex queries, and built scalable data models to enhance analytics efficiency. Adept at designing and orchestrating end-to-end data workflows to drive business insights. Passionate about leveraging data-driven solutions to solve real-world challenges. Holds a Master’s in Computer Science (3.83 GPA) and DP-203 certification. Seeking opportunities to innovate and contribute to cutting-edge data engineering solutions.
            </p>
        </div>
    </section>

    <section class="skills" id="skills">
      <div class="container">
          <h2 class="section-title">Skills</h2>
          <div class="skills-grid">
              <div class="skills-category">
                  <h3>Certifications</h3>
                  <div class="skills-list">
                      <span>Microsoft Certified: Azure Data Engineer Associate</span>
                      <span>LinkedIn - Power BI Essential Training</span>
                      <span>Udemy - Azure Databricks & Spark for Data Engineering</span>
                      <span>Dell Technologies - DELL CLIENT FOUNDATIONS 2021</span>
                      <span>Accenture - Data Analytics and Visualization Job Simulation</span>
                    
                  </div>
              </div>
              <div class="skills-category">
                  <h3>Frameworks</h3>
                  <div class="skills-list">
                    <span>Python</span>
                    <span>SQL</span>
                    <span>Java</span>
                    <span>PySpark</span>
                    <span>Scala</span>
                    <span>Web Technologies</span>
                    <span>Hadoop</span>
                    <span>Spark</span>
                    <span>Kafka</span>
                    <span>Hive</span>
                    <span>MySQL</span>
                    <span>PostgreSQL</span>
                    <span>Azure SQL Database</span>
                  </div>
              </div>
              <div class="skills-category">
                  <h3>Tools</h3>
                  <div class="skills-list">
                    <span>Fivetran</span>
                    <span>Snowflake</span>
                    <span>VS Code</span>
                    <span>PyCharm</span>
                    <span>Git</span>
                    <span>Jenkins</span>
                    <span>CI/CD</span>
                    <span>Azure (Data Factory, Databricks, Data Lake)</span>
                    <span>AWS (EMR, S3, Glue, Redshift)</span>
                    <span>Power BI</span>
                    <span>Tableau</span>
                    <span>Python Visualization Libraries</span>
                  </div>
              
          </div>
      </div>
  </section>
  
    <!-- Projects Section -->
    <section class="projects" id="projects">
        <div class="container">
            <h2 class="section-title">Projects</h2>
            <div class="projects-grid">
                <div class="project-card">
                    <h3>Formula 1 Data Analysis</h3>
                    <p> Built a data pipeline in Azure Databricks to transform Ergast API data, leveraging Delta Lake for storage and Azure
                        Data Factory for orchestration, and visualized insights using Power BI.</p>
                    <p>Developed supporting notebooks and SQL scripts to manage incremental data loads, ensuring data integrity and continuous updates</p>
                    <div class="tech-tags">
                        <span>Databricks</span>
                        <span>Pyspark</span>
                        <span>SQL</span>
                        <span>Azure DataLake Storage Gen2</span>
                        <span>Azure Data Factory</span>
                    </div>
                </div>
                <div class="project-card">
                    <h3>Weather Data ETL pipeline</h3>
                    <p>Built a simple ETL pipeline that collects daily weather data from a public API using Python, stores it in SQL, and
                        generates summary reports.</p>
                    <div class="tech-tags">
                        <span>Airflow</span>
                        <span>DAGS</span>
                        <span>Docker</span>
                        <span>AWS</span>
                        <span>Python</span>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Experience Section -->
    <section class="experience" id="experience">
        <div class="container">
            <h2 class="section-title">Experience</h2>
            <div class="experience-timeline">
                <div class="experience-card">
                    <div class="experience-header">
                        <div>
                            <h3>Research Assistant</h3>
                            <p class="company">SalukiTech Servce Center - Research Assistant</p>
                        </div>
                        <div class="experience-meta">
                            <p>Carbondale, USA</p>
                            <p>Feb 2023 - December 2024</p>
                        </div>
                    </div>
                    <ul class="experience-points">
                        <li>Automated data integration by connecting Fivetran to external data sources to extract and load IT funding and depart-
                            mental spending data into Snowflake, reducing manual data integration efforts by 50%.</li>
                        <li>Orchestrated end-to-end data pipelines using Azure Data Factory, ensuring seamless coordination between Fivetran syncs,
                            Snowflake transformations, and Power BI exports.</li>
                        <li> Developed complex SQL queries using CTEs (Common Table Expressions) and window functions to analyze spending
                            trends, track budget utilization, and identify cost-saving opportunities.</li>
                        <li>Built efficient data models in Snowflake to consolidate and analyze IT funding and spending data, improving query
                            performance by 30% and enabling real-time insights.</li>
                        <li> Created interactive Power BI dashboards to visualize IT funding allocations, departmental spending, and vendor perfor-
                            mance, providing actionable insights for the Resource Allocation.</li>
                    </ul>
                </div>

                

                <div class="experience-card">
                    <div class="experience-header">
                        <div>
                            <h3>DATA ENGINEER</h3>
                            <p class="company"></p>
                        </div>
                        <div class="experience-meta">
                            <p>Accenture, India</p>
                            <p>October 2022 – Jan 2023</p>
                        </div>
                    </div>
                    <ul class="experience-points">
                        <li>Contributed to the successful migration of 50TB of healthcare data to Azure Data Lake Storage Gen2, enabling scalable
                            data processing and improving data accessibility for analytics.</li>
                        <li> Supported the implementation of Medallion architecture in Azure Databricks, transforming raw data into bronze, silver,
                            and gold layers to prepare datasets for workflows.</li>
                        <li>Developed and optimized ETL pipelines using Databricks (PySpark, SQL), and orchestrated the entire workflow with
                            Azure Data Factory, ensuring seamless data integration and efficient processing</li>
                         <li>Configured secure data access using Azure Key Vault and ADLS Gen2, ensuring compliance with HIPAA and other
                            healthcare data security and privacy standards.</li> 
                         <li>Assisted in the development of Power BI dashboards and prepared feature-rich datasets to support AI/ML initiatives,
                            enhancing clinical decision-making and operational efficiency.</li>   
                    </ul>
                </div>

                <div class="experience-card">
                    <div class="experience-header">
                        <div>
                            <h3>Research Assistant</h3>
                            <p class="company">SalukiTech Servce Center - Research Assistant</p>
                        </div>
                        <div class="experience-meta">
                            <p>Cognizant, India</p>
                            <p>Feb 2022 - Oct 2022</p>
                        </div>
                    </div>
                    <ul class="experience-points">
                        <li> Developed Python scripts using pandas for data cleaning and preprocessing before AWS ingestion.</li>
                        <li>Acquired initial exposure to Hive for data querying and Kafka for simple producer/consumer setup, demonstrating
                        understanding of big data fundamentals.</li>
                        <li>Gained hands-on experience building basic ETL pipelines using AWS S3 for storage and Glue Crawler for schema detection,
                        successfully processed CSV files containing customer transaction data.</li>
                        <li> Applied practical knowledge of EventBridge for scheduling daily Glue Jobs, configuring SNS notifications for job comple-
                        tion alerts, and using Step Functions for simple workflow orchestration.</li>
                        <li>Wrote SQL queries to analyze data in Redshift, focusing on basic aggregations, joins, and filtering to support weekly sales
                        reporting requirements.</li>
                    </ul>
                </div>
            </div>
        </div>


        

      
    </div>
</div>

    </section>

    <!-- Contact Section -->
    <section class="contact" id="contact">
        <div class="container">
            <h2 class="section-title">Contact</h2>
            <div class="contact-content">
                <a href="mailto:meghanareddy1818@gmail.com" class="contact-item">
                    <i class="fas fa-envelope"></i>
                    <span>meghanareddy1818@gmail.com</span>
                </a>
                <a href="tel:+16183195600" class="contact-item">
                    <i class="fas fa-phone"></i>
                    <span>+1-618-319-5600</span>
                </a>
                <a href="https://www.linkedin.com/in/meghanareddy18/" target="_blank" class="contact-item">
                    <i class="fab fa-linkedin"></i>
                    <span>LinkedIn</span>
                </a>
            </div>
        </div>
    </section>

    <!-- Footer -->
    <footer>
        <div class="container">
            <p>&copy; <span id="currentYear"></span> Meghana Reddy. All rights reserved.</p>
        </div>
    </footer>

    <script src="portfolio3.js"></script>
</body>
</html>